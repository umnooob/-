工作内容：学习深度学习基础原理，包括神经网络、反向传播和损失函数等。
工作进展：今天我开始了我的毕设，着手学习深度学习的基础知识，主要包括神经网络、反向传播和损失函数等方面。我使用了Coursera上面的《深度学习》课程，在完成了前面的授课视频和作业后，对于深度学习的理解更为深入了。
接着，我利用PyTorch对一些小型的图像分类任务进行了实践。在实践过程中，我通过调整一些超参数、学习率等参数，提高了模型的精度，也克服了一些编码和调试时遇到的困难。
总结：今天的学习任务十分实践，我通过题目错解题、错解题，从而更深入地理解深度学习的基本原理和常用技术。在后续的训练和研究过程中，我会努力将这些理论和技术贯彻到我的毕设中去。
---
工作内容：学习图神经网络的基本概念和应用场景，以及GCN, GAT, GraphSAGE等常用的图神经网络模型的原理和实现方法。
工作进展：今天我着重学习了与毕设密切相关的图神经网络的相关知识。在学习图神经网络方面，我首先了解了图的概念以及图的数据结构，在此备录一下。之后我逐一学习了GCN, GAT, GraphSAGE等各种图神经网络的原理和实现方法，并在Google Colab上进行了实现和调试。最后，我使用一些常见的图数据集，例如Cora和Citeseer等数据集，进行了实验。
总结：通过今天的学习，我深入了解了图神经网络技术，也熟悉了常见的图神经网络模型以及这些模型在实际应用中的优劣性和适用场合等。在后续的研究和探索中，我会将这些理论和技术应用于我的毕设中去。
---
工作内容：编写代码并实践了解GCN, GAT, GraphSAGE等图神经网络模型的使用，使用一些常见的开源深度学习框架进行实现和调试。
工作进展：继昨天的学习之后，今天我在自己的电脑上结合自己的数据集实践了学到的GCN、GAT、GraphSAGE等常用图神经网络模型。同时，我还学会了如何使用Python中的PyTorch和Tensorflow框架来实现图神经网络，并将自己实践的模型在自己的数据集上进行了实验。在实验过程中，我遇到了一些挑战，比如模型的过拟合、超参数调度和模型收敛等问题。当然我也在不断的调整参数和算法优化以解决这些问题。
总结：通过今天的实验，我学会了如何使用Python中流行的深度学习框架(PyTorch和TensorFlow）结合图神经网络的相关技术，将其应用于解决自己问题的实际任务中，如节点/图分类等，同时还提高了自己的编程和调试的技能。
--- 
工作内容：阅读关于图神经网络最新研究成果的论文，并分析这些研究成果的应用前景以及与GCN, GAT, GraphSAGE等模型的区别和优劣势。
工作进展：今天，我在Google Scholar等学术数据库中搜索有关最新的图神经网络研究成果的论文，并找到了一些受引用率较高的相关论文。在阅读这些论文时，我发现这些研究成果相对于GCN、GAT、GraphSAGE等图神经网络的原理结构上有所发展，以及更强的性能表现，如 更快的训练速度、更低的错误率等。
并且也连带对比了一下GCN、GAT、GraphSAGE等模型的优缺点和适用场。通过阅读论文并比较分析，我得出了一系列对于各个模型的认识和我对我的毕设的建议。
总结：通过今天的研究，我对于当前图神经网络研究的进展及其未来趋势有了更深刻的认识，为后续的毕设的实现和优化提供了一定的指导。
---
工作内容：进行小型实践项目，比如简单的图分类任务，评估不同的图神经网络模型对于该任务的性能表现，总结和对比GCN, GAT, GraphSAGE等模型的表现和使用场景。
工作进展：今天我进行了一些小型实践项目，如图分类任务，使用了GCN和GAT等常见的图神经网络模型，并通过一些参数的调节和数据的优化，对性能进行了评估和对比。分析了不同的深度学习框架对实验结果的影响。最终，对比总结了不同模型的测试结果和应用场景，总结了这次毕设中的学习和实践经验。
总结：在图神经网络的实践中，我收获到了很多。比如实战经验、对图神经网络各种成果的理解以及对深度学习框架的使用熟练度。同时，也对各种模型的优缺点和应用进行了深入的思考和总结，为毕设的进一步完善奠定了坚实的基础。